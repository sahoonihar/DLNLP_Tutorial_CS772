{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import spacy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TEXT = data.Field(lower = True, batch_first = True)\n",
    "UD_TAGS = data.Field(unk_token = None, batch_first=True)\n",
    "PTB_TAGS = data.Field(unk_token = None, batch_first=True)\n",
    "        \n",
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))\n",
    "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = 1,\n",
    "                 vectors = GloVe(name = \"42B\", dim=300))\n",
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_hiddens, num_layers, num_labels, pad_idx, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, num_hiddens, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * num_hiddens, num_labels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        outputs, (h_state, c_state) = self.lstm(embeddings)\n",
    "        return self.fc(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(16655, 300, padding_idx=1)\n",
       "  (lstm): LSTM(300, 64, num_layers=4, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBED_DIM = TEXT.vocab.vectors.shape[1]\n",
    "NUM_HIDDENS = 64\n",
    "NUM_LABELS = len(UD_TAGS.vocab)\n",
    "NUM_LAYERS = 4 \n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "EPOCHS = 10 \n",
    "LR = 5  \n",
    "\n",
    "model = BiLSTM(VOCAB_SIZE, EMBED_DIM, NUM_HIDDENS, NUM_LAYERS, NUM_LABELS, PAD_IDX)\n",
    "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / y[non_pad_elements].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        text, tags = batch.text, batch.udtags\n",
    "        predicted_tags = model(text)\n",
    "        predicted_tags = predicted_tags.view(-1, predicted_tags.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        loss = criterion(predicted_tags, tags)\n",
    "        acc = categorical_accuracy(predicted_tags, tags, TAG_PAD_IDX)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += acc.item()\n",
    "        total_count += 1\n",
    "        if batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, batch_idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            text, tags = batch.text, batch.udtags\n",
    "            predicted_tags = model(text)\n",
    "            predicted_tags = predicted_tags.view(-1, predicted_tags.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            acc = categorical_accuracy(predicted_tags, tags, TAG_PAD_IDX)\n",
    "            total_acc += acc.item()\n",
    "            total_count += 1\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    10/   98 batches | accuracy    0.949\n",
      "| epoch   1 |    20/   98 batches | accuracy    0.944\n",
      "| epoch   1 |    30/   98 batches | accuracy    0.946\n",
      "| epoch   1 |    40/   98 batches | accuracy    0.945\n",
      "| epoch   1 |    50/   98 batches | accuracy    0.947\n",
      "| epoch   1 |    60/   98 batches | accuracy    0.949\n",
      "| epoch   1 |    70/   98 batches | accuracy    0.948\n",
      "| epoch   1 |    80/   98 batches | accuracy    0.947\n",
      "| epoch   1 |    90/   98 batches | accuracy    0.949\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  6.03s | valid accuracy    0.859 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    10/   98 batches | accuracy    0.951\n",
      "| epoch   2 |    20/   98 batches | accuracy    0.952\n",
      "| epoch   2 |    30/   98 batches | accuracy    0.952\n",
      "| epoch   2 |    40/   98 batches | accuracy    0.952\n",
      "| epoch   2 |    50/   98 batches | accuracy    0.952\n",
      "| epoch   2 |    60/   98 batches | accuracy    0.951\n",
      "| epoch   2 |    70/   98 batches | accuracy    0.946\n",
      "| epoch   2 |    80/   98 batches | accuracy    0.951\n",
      "| epoch   2 |    90/   98 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  6.07s | valid accuracy    0.869 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    10/   98 batches | accuracy    0.954\n",
      "| epoch   3 |    20/   98 batches | accuracy    0.955\n",
      "| epoch   3 |    30/   98 batches | accuracy    0.957\n",
      "| epoch   3 |    40/   98 batches | accuracy    0.954\n",
      "| epoch   3 |    50/   98 batches | accuracy    0.952\n",
      "| epoch   3 |    60/   98 batches | accuracy    0.950\n",
      "| epoch   3 |    70/   98 batches | accuracy    0.954\n",
      "| epoch   3 |    80/   98 batches | accuracy    0.957\n",
      "| epoch   3 |    90/   98 batches | accuracy    0.955\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.19s | valid accuracy    0.868 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    10/   98 batches | accuracy    0.960\n",
      "| epoch   4 |    20/   98 batches | accuracy    0.965\n",
      "| epoch   4 |    30/   98 batches | accuracy    0.964\n",
      "| epoch   4 |    40/   98 batches | accuracy    0.965\n",
      "| epoch   4 |    50/   98 batches | accuracy    0.964\n",
      "| epoch   4 |    60/   98 batches | accuracy    0.965\n",
      "| epoch   4 |    70/   98 batches | accuracy    0.964\n",
      "| epoch   4 |    80/   98 batches | accuracy    0.966\n",
      "| epoch   4 |    90/   98 batches | accuracy    0.962\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  5.95s | valid accuracy    0.878 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    10/   98 batches | accuracy    0.966\n",
      "| epoch   5 |    20/   98 batches | accuracy    0.966\n",
      "| epoch   5 |    30/   98 batches | accuracy    0.967\n",
      "| epoch   5 |    40/   98 batches | accuracy    0.965\n",
      "| epoch   5 |    50/   98 batches | accuracy    0.967\n",
      "| epoch   5 |    60/   98 batches | accuracy    0.967\n",
      "| epoch   5 |    70/   98 batches | accuracy    0.966\n",
      "| epoch   5 |    80/   98 batches | accuracy    0.965\n",
      "| epoch   5 |    90/   98 batches | accuracy    0.967\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  5.92s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    10/   98 batches | accuracy    0.969\n",
      "| epoch   6 |    20/   98 batches | accuracy    0.966\n",
      "| epoch   6 |    30/   98 batches | accuracy    0.966\n",
      "| epoch   6 |    40/   98 batches | accuracy    0.967\n",
      "| epoch   6 |    50/   98 batches | accuracy    0.969\n",
      "| epoch   6 |    60/   98 batches | accuracy    0.967\n",
      "| epoch   6 |    70/   98 batches | accuracy    0.967\n",
      "| epoch   6 |    80/   98 batches | accuracy    0.967\n",
      "| epoch   6 |    90/   98 batches | accuracy    0.968\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  6.01s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    10/   98 batches | accuracy    0.970\n",
      "| epoch   7 |    20/   98 batches | accuracy    0.965\n",
      "| epoch   7 |    30/   98 batches | accuracy    0.968\n",
      "| epoch   7 |    40/   98 batches | accuracy    0.967\n",
      "| epoch   7 |    50/   98 batches | accuracy    0.967\n",
      "| epoch   7 |    60/   98 batches | accuracy    0.968\n",
      "| epoch   7 |    70/   98 batches | accuracy    0.967\n",
      "| epoch   7 |    80/   98 batches | accuracy    0.969\n",
      "| epoch   7 |    90/   98 batches | accuracy    0.965\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  5.96s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    10/   98 batches | accuracy    0.967\n",
      "| epoch   8 |    20/   98 batches | accuracy    0.968\n",
      "| epoch   8 |    30/   98 batches | accuracy    0.966\n",
      "| epoch   8 |    40/   98 batches | accuracy    0.968\n",
      "| epoch   8 |    50/   98 batches | accuracy    0.967\n",
      "| epoch   8 |    60/   98 batches | accuracy    0.967\n",
      "| epoch   8 |    70/   98 batches | accuracy    0.967\n",
      "| epoch   8 |    80/   98 batches | accuracy    0.970\n",
      "| epoch   8 |    90/   98 batches | accuracy    0.966\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  6.00s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    10/   98 batches | accuracy    0.965\n",
      "| epoch   9 |    20/   98 batches | accuracy    0.966\n",
      "| epoch   9 |    30/   98 batches | accuracy    0.969\n",
      "| epoch   9 |    40/   98 batches | accuracy    0.969\n",
      "| epoch   9 |    50/   98 batches | accuracy    0.967\n",
      "| epoch   9 |    60/   98 batches | accuracy    0.968\n",
      "| epoch   9 |    70/   98 batches | accuracy    0.969\n",
      "| epoch   9 |    80/   98 batches | accuracy    0.965\n",
      "| epoch   9 |    90/   98 batches | accuracy    0.968\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  6.01s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    10/   98 batches | accuracy    0.966\n",
      "| epoch  10 |    20/   98 batches | accuracy    0.969\n",
      "| epoch  10 |    30/   98 batches | accuracy    0.969\n",
      "| epoch  10 |    40/   98 batches | accuracy    0.968\n",
      "| epoch  10 |    50/   98 batches | accuracy    0.967\n",
      "| epoch  10 |    60/   98 batches | accuracy    0.966\n",
      "| epoch  10 |    70/   98 batches | accuracy    0.969\n",
      "| epoch  10 |    80/   98 batches | accuracy    0.965\n",
      "| epoch  10 |    90/   98 batches | accuracy    0.968\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  5.87s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(val_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy    0.880\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

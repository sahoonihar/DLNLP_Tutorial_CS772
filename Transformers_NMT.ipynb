{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers-NMT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def increase_font():\n",
        "  from IPython.display import Javascript\n",
        "  display(Javascript('''\n",
        "  for (rule of document.styleSheets[0].cssRules){\n",
        "    if (rule.selectorText=='body') {\n",
        "      rule.style.fontSize = '20px'\n",
        "      break\n",
        "    }\n",
        "  }\n",
        "  '''))\n",
        "increase_font()\n",
        "get_ipython().events.register('pre_run_cell', increase_font)\n",
        "print(\"Hello Everyone\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "4OmVLC9AQBnV",
        "outputId": "d489ea53-ce21-48ac-d09f-aac71a525650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Everyone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Dependencies**"
      ],
      "metadata": {
        "id": "FMVFLVC7hbTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Files\n",
        "!pip3 install gdown -U\n",
        "\n",
        "# Neural Machine Translation Library\n",
        "!pip3 install OpenNMT-py\n",
        "\n",
        "!git clone https://github.com/moses-smt/mosesdecoder.git\n",
        "!pip3 install indic_nlp_library\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!pip3 install -r indic_nlp_library/requirements.txt\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "\n",
        "!pip3 install https://github.com/rsennrich/subword-nmt/archive/master.zip\n",
        "!pip3 install sacrebleu\n",
        "!pip3 install ctranslate2\n",
        "!pip3 install mosestokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RGKTD38shB-J",
        "outputId": "6ac7254a-349b-4c7a-fade-584f1243d99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14774 sha256=db8beb8c9441ca045567984bda60009f6711470e083797d6bc8d93742cd7fe37\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/c3/0e/c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.2.2\n",
            "    Uninstalling gdown-4.2.2:\n",
            "      Successfully uninstalled gdown-4.2.2\n",
            "Successfully installed gdown-4.4.0\n",
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-2.2.0-py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting waitress\n",
            "  Downloading waitress-2.1.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (1.1.4)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (2.8.0)\n",
            "Collecting torchtext==0.5.0\n",
            "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (1.10.0+cu111)\n",
            "Collecting pyonmttok<2,>=1.23\n",
            "  Downloading pyonmttok-1.31.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 263 kB/s \n",
            "\u001b[?25hCollecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.21.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.44.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.2.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py) (2.0.1)\n",
            "Installing collected packages: sentencepiece, waitress, torchtext, pyonmttok, configargparse, OpenNMT-py\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed OpenNMT-py-2.2.0 configargparse-1.5.3 pyonmttok-1.31.0 sentencepiece-0.1.96 torchtext-0.5.0 waitress-2.1.1\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 148090, done.\u001b[K\n",
            "remote: Counting objects: 100% (518/518), done.\u001b[K\n",
            "remote: Compressing objects: 100% (223/223), done.\u001b[K\n",
            "remote: Total 148090 (delta 319), reused 443 (delta 292), pack-reused 147572\u001b[K\n",
            "Receiving objects: 100% (148090/148090), 129.87 MiB | 18.57 MiB/s, done.\n",
            "Resolving deltas: 100% (114345/114345), done.\n",
            "Collecting indic_nlp_library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.3.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic_nlp_library) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic_nlp_library) (1.21.5)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic_nlp_library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic_nlp_library) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->indic_nlp_library) (1.15.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic_nlp_library) (1.8.6)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.9.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (0.7.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (57.4.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.11.3)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (0.17.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (21.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.3.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (3.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->indic_nlp_library) (1.1.5)\n",
            "Installing collected packages: sphinx-rtd-theme, sphinx-argparse, morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.81 morfessor-2.0.6 sphinx-argparse-0.3.1 sphinx-rtd-theme-1.0.0\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1325, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 1325 (delta 84), reused 89 (delta 41), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1325/1325), 9.57 MiB | 11.83 MiB/s, done.\n",
            "Resolving deltas: 100% (688/688), done.\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.7/dist-packages (from -r indic_nlp_library/requirements.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.7/dist-packages (from -r indic_nlp_library/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.7/dist-packages (from -r indic_nlp_library/requirements.txt (line 3)) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r indic_nlp_library/requirements.txt (line 4)) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r indic_nlp_library/requirements.txt (line 5)) (1.21.5)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (1.8.6)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (1.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (0.17.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.9.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (0.7.12)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r indic_nlp_library/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (3.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->-r indic_nlp_library/requirements.txt (line 1)) (1.1.5)\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 30.64 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Collecting subword_nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword_nmt) (4.63.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: mock, subword-nmt\n",
            "Successfully installed mock-4.0.3 subword-nmt-0.3.8\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (1.21.5)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.4 portalocker-2.4.0 sacrebleu-2.0.0\n",
            "Collecting ctranslate2\n",
            "  Downloading ctranslate2-2.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ctranslate2) (1.21.5)\n",
            "Collecting pyyaml<7,>=5.3\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 20.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyyaml, ctranslate2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed ctranslate2-2.15.1 pyyaml-6.0\n",
            "Collecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from mosestokenizer) (0.6.2)\n",
            "Collecting openfile\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "Collecting toolwrapper\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "Building wheels for collected packages: mosestokenizer, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49189 sha256=932471b3675c43b4014925c544141305588bcc48a06e304c81dae5bd7a81eff6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/35/f7/af1258779a0b890abc3c79481460c597cb1f3659d0603cfb9d\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3353 sha256=7d92e2f62187ba766c9f29c049cd60a4f6a85ba8680add6ffe8c7b8398728cf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4f/33/54741ffe08e38ececb1d28068a153729b4fe820bafa0a0691f\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6161 sha256=d6dd9aafcc8fe6f15e13c01e7ba8e8a1b33646d4570f3999c03e8db060bfdd10\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/e9/914cf8fa71f0141f9314f862538d1218fcf2b94542a0fb7d35\n",
            "Successfully built mosestokenizer toolwrapper uctools\n",
            "Installing collected packages: uctools, toolwrapper, openfile, mosestokenizer\n",
            "Successfully installed mosestokenizer-1.2.1 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "export PYTHONPATH=$PYTHONPATH:/content/indic_nlp_library\n",
        "export INDIC_RESOURCES_PATH=/content/indic_nlp_resources\n",
        "\n",
        "echo $INDIC_RESOURCES_PATH\n",
        "echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "_GhUi5FAmqTS",
        "outputId": "b8a37aaa-88d6-4c17-cb22-2861821a81f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/indic_nlp_resources\n",
            "/env/python:/content/indic_nlp_library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Data**"
      ],
      "metadata": {
        "id": "jCrwjyZghhzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download Samanantar Dataset**\n",
        "Source: https://indicnlp.ai4bharat.org/samanantar/"
      ],
      "metadata": {
        "id": "s4EuiwoBsTEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-mr.zip\n",
        "!unzip en-mr.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "jKeAIwzuhZM1",
        "outputId": "42cfad90-c59f-4732-820e-01766fdfd13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-06 18:29:56--  https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-mr.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.152.128, 173.194.194.128, 173.194.198.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.152.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 769637789 (734M) [application/zip]\n",
            "Saving to: ‘en-mr.zip’\n",
            "\n",
            "en-mr.zip           100%[===================>] 733.98M   136MB/s    in 5.9s    \n",
            "\n",
            "2022-04-06 18:30:02 (125 MB/s) - ‘en-mr.zip’ saved [769637789/769637789]\n",
            "\n",
            "Archive:  en-mr.zip\n",
            "   creating: en-mr/\n",
            " extracting: en-mr/train.mr          \n",
            " extracting: en-mr/train.en          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l en-mr/*"
      ],
      "metadata": {
        "id": "Rx4NbOd1NJsW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "90bbcf79-18c0-4026-d609-fd5d61bcb580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3288874 en-mr/train.en\n",
            "  3288874 en-mr/train.mr\n",
            "  6577748 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split Data into Train, Test and Validation sets**"
      ],
      "metadata": {
        "id": "UWQJ4ZL5h_uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sourceValidLen = 1000\n",
        "targetValidLen = 1000\n",
        "\n",
        "sourceTestLen = 1000\n",
        "targetTestLen = 1000\n",
        "\n",
        "sourceTrainLen = 20000\n",
        "targetTrainLen = 20000"
      ],
      "metadata": {
        "id": "o3W4cDBoMfSm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bfc2bc0a-7aa9-4598-d328-ac9f5acdcce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "sourceData = open(\"en-mr/train.en\", 'r').readlines()\n",
        "targetData = open(\"en-mr/train.mr\", 'r').readlines()\n",
        "\n",
        "sourceValid = sourceData[0:sourceValidLen]\n",
        "targetValid = targetData[0:targetValidLen]\n",
        "\n",
        "sourceTest = sourceData[sourceValidLen:sourceValidLen + sourceTestLen]\n",
        "targetTest = targetData[targetValidLen:targetValidLen + targetTestLen]\n",
        "\n",
        "sourceTrain = sourceData[sourceValidLen + sourceTestLen:sourceValidLen + sourceTestLen + sourceTrainLen]\n",
        "targetTrain = targetData[targetValidLen + targetTestLen:targetValidLen + targetTestLen + targetTrainLen]\n",
        "\n",
        "sourceTestFile = open(\"data/test.en\", \"w+\")\n",
        "for line in sourceTest:\n",
        "  sourceTestFile.write(line.strip(\"\\n\") + \"\\n\")\n",
        "sourceTestFile.close()\n",
        "\n",
        "targetTestFile = open(\"data/test.mr\", \"w+\")\n",
        "for line in targetTest:\n",
        "  targetTestFile.write(line.strip(\"\\n\") + \"\\n\")\n",
        "targetTestFile.close()\n",
        "\n",
        "sourceValidFile = open(\"data/valid.en\", \"w+\")\n",
        "for line in sourceValid:\n",
        "  sourceValidFile.write(line.strip(\"\\n\") + \"\\n\")\n",
        "sourceValidFile.close()\n",
        "\n",
        "targetValidFile = open(\"data/valid.mr\", \"w+\")\n",
        "for line in targetValid:\n",
        "  targetValidFile.write(line.strip(\"\\n\") + \"\\n\")\n",
        "targetValidFile.close()\n",
        "\n",
        "sourceTrainFile = open(\"data/train.en\", \"w+\")\n",
        "for line in sourceTrain:\n",
        "  sourceTrainFile.write(line.strip(\"\\n\") + \"\\n\")\n",
        "sourceTrainFile.close()\n",
        "\n",
        "targetTrainFile = open(\"data/train.mr\", \"w+\")\n",
        "for line in targetTrain:\n",
        "  targetTrainFile.write(line.strip(\"\\n\") + \"\\n\")\n",
        "targetTrainFile.close()\n"
      ],
      "metadata": {
        "id": "BdpNFC51iKzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "529939d0-c7a9-492b-ae70-edcee1444cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess Data**"
      ],
      "metadata": {
        "id": "AJnwt5hJlICx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lowercase English Text**"
      ],
      "metadata": {
        "id": "fLY-kcSKlKca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/mosesdecoder/scripts/tokenizer/lowercase.perl < data/train.en > data/train-low.en\n",
        "!/content/mosesdecoder/scripts/tokenizer/lowercase.perl < data/test.en > data/test-low.en\n",
        "!/content/mosesdecoder/scripts/tokenizer/lowercase.perl < data/valid.en > data/valid-low.en"
      ],
      "metadata": {
        "id": "BhUq85FUnC7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0351fd62-8208-41da-9bde-db4d99d4b223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "z2RFaUu2s2Q3",
        "outputId": "1d984b8d-e340-4222-8795-fbffaeec6864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some are against it.\n",
            "[ Footnote] Capernaum was considered to be Jesus home city in the district of Galilee. Mark 2: 1.\n",
            "PM Narendra Modi and Amit Shah have already held rallies in the state.\n",
            "childrens education\n",
            "In many places there had been clashes.\n",
            "He had joined BJP before the Rajya Sabha polls.\n",
            "Uddhav Thackeray had visited Ayodhya before the Lok Sabha polls.\n",
            "Further arrests are expected in the future.\n",
            "Dont like it.\n",
            "So, lets say we just put one electrode of lithium here another electrode of something some counter electrode here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train-low.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "W9nxnXgTs5ek",
        "outputId": "a0ffa492-9a7e-4320-c3b1-b54282b635c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some are against it.\n",
            "[ footnote] capernaum was considered to be jesus home city in the district of galilee. mark 2: 1.\n",
            "pm narendra modi and amit shah have already held rallies in the state.\n",
            "childrens education\n",
            "in many places there had been clashes.\n",
            "he had joined bjp before the rajya sabha polls.\n",
            "uddhav thackeray had visited ayodhya before the lok sabha polls.\n",
            "further arrests are expected in the future.\n",
            "dont like it.\n",
            "so, lets say we just put one electrode of lithium here another electrode of something some counter electrode here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenize English Test**"
      ],
      "metadata": {
        "id": "IPxJgjROnlaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/mosesdecoder/scripts/tokenizer/tokenizer.perl < data/train-low.en > data/train-tok.en\n",
        "!/content/mosesdecoder/scripts/tokenizer/tokenizer.perl < data/test-low.en > data/test-tok.en\n",
        "!/content/mosesdecoder/scripts/tokenizer/tokenizer.perl < data/valid-low.en > data/valid-tok.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "GBCZpfKvn3N8",
        "outputId": "4b2198cc-0419-4b7e-99bc-620e9fb8a905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 1\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 1\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train-tok.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "bFNh8kEHs9XO",
        "outputId": "cf026fed-f490-42f6-dd1f-3d24aa308a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some are against it .\n",
            "&#91; footnote &#93; capernaum was considered to be jesus home city in the district of galilee. mark 2 : 1 .\n",
            "pm narendra modi and amit shah have already held rallies in the state .\n",
            "childrens education\n",
            "in many places there had been clashes .\n",
            "he had joined bjp before the rajya sabha polls .\n",
            "uddhav thackeray had visited ayodhya before the lok sabha polls .\n",
            "further arrests are expected in the future .\n",
            "dont like it .\n",
            "so , lets say we just put one electrode of lithium here another electrode of something some counter electrode here .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Normalize Marathi Text**"
      ],
      "metadata": {
        "id": "9TOjQnTboRqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 indic_nlp_library/indicnlp/normalize/indic_normalize.py data/train.mr data/train-norm.mr mr\n",
        "!python3 indic_nlp_library/indicnlp/normalize/indic_normalize.py data/valid.mr data/valid-norm.mr mr\n",
        "!python3 indic_nlp_library/indicnlp/normalize/indic_normalize.py data/test.mr data/test-norm.mr mr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RUhMy45RoVCz",
        "outputId": "29ea9ef6-e5a8-402f-9408-b77a83d4121d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train.mr "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "pvDBuFwbtB-9",
        "outputId": "4e728617-f574-4358-b40a-a56a258d8f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तर काही जण विरोधही करत आहेत.\n",
            "या माहितीचे परीक्षण करताना आपल्याला कळेल, की आजही येशूचा लोकांवर प्रभाव का पडत आहे. (w१० - E ०४ / ०१)\n",
            "नरेंद्र मोदी आणि अमित शहा यांनी देशात अराजक माजवले आहे.\n",
            "मुलाचे शिक्षण\n",
            "अनेक ठिकाणी पडझडीच्या घटना घडल्या.\n",
            "मात्र विधानसभा निवडणुकीआधी ते भाजपमध्ये गेले.\n",
            "लोकसभा निवडणुकीच्या आधी पक्षप्रमुख उद्धव ठाकरे यांनी अयोध्येचा दौरा केला होता.\n",
            "येत्या काळात आणखी काहींची धरपकड केली जाण्याची शक्यता आहे.\n",
            "अजिबात आवडला नाही.\n",
            "तर, आपण इथे लिथियमचे एक इलेक्ट्रोड (electrode) ठेवू या.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train-norm.mr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "n1B_DKEdtF-l",
        "outputId": "2148e966-f07d-43f7-b0fe-71993af884f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तर काही जण विरोधही करत आहेत.\n",
            "या माहितीचे परीक्षण करताना आपल्याला कळेल, की आजही येशूचा लोकांवर प्रभाव का पडत आहे. (w१० - E ०४ / ०१)\n",
            "नरेंद्र मोदी आणि अमित शहा यांनी देशात अराजक माजवले आहे.\n",
            "मुलाचे शिक्षण\n",
            "अनेक ठिकाणी पडझडीच्या घटना घडल्या.\n",
            "मात्र विधानसभा निवडणुकीआधी ते भाजपमध्ये गेले.\n",
            "लोकसभा निवडणुकीच्या आधी पक्षप्रमुख उद्धव ठाकरे यांनी अयोध्येचा दौरा केला होता.\n",
            "येत्या काळात आणखी काहींची धरपकड केली जाण्याची शक्यता आहे.\n",
            "अजिबात आवडला नाही.\n",
            "तर, आपण इथे लिथियमचे एक इलेक्ट्रोड (electrode) ठेवू या.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenize Marathi Text**"
      ],
      "metadata": {
        "id": "tnKqjv3NpaaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Uncomment if the part after `if __name__ == '__main__':` in the file `indic_nlp_library/indicnlp/tokenize/indic_tokenize.py`"
      ],
      "metadata": {
        "id": "J592MgEhT9yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 indic_nlp_library/indicnlp/tokenize/indic_tokenize.py data/train-norm.mr data/train-tok.mr mr\n",
        "!python3 indic_nlp_library/indicnlp/tokenize/indic_tokenize.py data/valid-norm.mr data/valid-tok.mr mr\n",
        "!python3 indic_nlp_library/indicnlp/tokenize/indic_tokenize.py data/test-norm.mr data/test-tok.mr mr"
      ],
      "metadata": {
        "id": "DLLVgktrpdGN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3059a543-d3e8-4469-e148-cbda28c0b00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/train-tok.mr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "XHydrr1ftJ0v",
        "outputId": "2d3f4ba9-927f-4323-ecec-ccd36024e027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तर काही जण विरोधही करत आहेत . \n",
            "या माहितीचे परीक्षण करताना आपल्याला कळेल , की आजही येशूचा लोकांवर प्रभाव का पडत आहे . ( w१० - E ०४ / ०१ ) \n",
            "नरेंद्र मोदी आणि अमित शहा यांनी देशात अराजक माजवले आहे . \n",
            "मुलाचे शिक्षण\n",
            "अनेक ठिकाणी पडझडीच्या घटना घडल्या . \n",
            "मात्र विधानसभा निवडणुकीआधी ते भाजपमध्ये गेले . \n",
            "लोकसभा निवडणुकीच्या आधी पक्षप्रमुख उद्धव ठाकरे यांनी अयोध्येचा दौरा केला होता . \n",
            "येत्या काळात आणखी काहींची धरपकड केली जाण्याची शक्यता आहे . \n",
            "अजिबात आवडला नाही . \n",
            "तर , आपण इथे लिथियमचे एक इलेक्ट्रोड ( electrode ) ठेवू या . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Apply Byte Pair Encoding (BPE)**"
      ],
      "metadata": {
        "id": "7HFF6cf4p-fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install https://github.com/rsennrich/subword-nmt/archive/master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "zG3paa97J4b0",
        "outputId": "4e6f85e0-51d1-4384-901a-d401b870b81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/rsennrich/subword-nmt/archive/master.zip\n",
            "  Downloading https://github.com/rsennrich/subword-nmt/archive/master.zip\n",
            "\u001b[K     - 133 kB 1.8 MB/s\n",
            "\u001b[?25hRequirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from subword-nmt==0.3.8) (4.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword-nmt==0.3.8) (4.63.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir codes\n",
        "!mkdir data/bpe\n",
        "\n",
        "!subword-nmt learn-bpe -s 8000 --num-workers 40 < data/train-tok.en > codes/codes.en\n",
        "\n",
        "!subword-nmt apply-bpe --num-workers 40 -c codes/codes.en < data/train-tok.en > data/bpe/train-bpe.en\n",
        "!subword-nmt apply-bpe --num-workers 40 -c codes/codes.en < data/test-tok.en > data/bpe/test-bpe.en\n",
        "!subword-nmt apply-bpe --num-workers 40 -c codes/codes.en < data/valid-tok.en > data/bpe/valid-bpe.en\n",
        "\n",
        "\n",
        "!subword-nmt learn-bpe --num-workers 40 -s 8000 < data/train-tok.mr > codes/codes.mr\n",
        "\n",
        "!subword-nmt apply-bpe --num-workers 40 -c codes/codes.mr < data/train-tok.mr > data/bpe/train-bpe.mr\n",
        "!subword-nmt apply-bpe --num-workers 40 -c codes/codes.mr < data/test-tok.mr > data/bpe/test-bpe.mr\n",
        "!subword-nmt apply-bpe --num-workers 40 -c codes/codes.mr < data/valid-tok.mr > data/bpe/valid-bpe.mr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "L6BzsCxjqDxy",
        "outputId": "afadff96-2683-44d3-b095-9dc9123ac6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘codes’: File exists\n",
            "mkdir: cannot create directory ‘data/bpe’: File exists\n",
            "100% 8000/8000 [00:10<00:00, 729.16it/s] \n",
            "100% 8000/8000 [00:18<00:00, 437.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download BPE Data and Codes"
      ],
      "metadata": {
        "id": "1KCTRUeXvjPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "!mkdir codes\n",
        "!mkdir data/bpe\n",
        "\n",
        "url = 'https://drive.google.com/drive/folders/1wGnMc4f-JPVj9mG8gX52FVxs3JSv7F1R?usp=sharing'\n",
        "gdown.download_folder(url, quiet=True)\n",
        "\n",
        "!cp en-mr-bpe/codes.en codes/codes.en\n",
        "!cp en-mr-bpe/codes.mr codes/codes.mr\n",
        "!cp en-mr-bpe/train-bpe.en data/bpe/train-bpe.en\n",
        "!cp en-mr-bpe/train-bpe.mr data/bpe/train-bpe.mr\n",
        "!cp en-mr-bpe/test-bpe.en data/bpe/test-bpe.en\n",
        "!cp en-mr-bpe/test-bpe.mr data/bpe/test-bpe.mr\n",
        "!cp en-mr-bpe/valid-bpe.en data/bpe/valid-bpe.en\n",
        "!cp en-mr-bpe/valid-bpe.mr data/bpe/valid-bpe.mr"
      ],
      "metadata": {
        "id": "hpE29kaRqw_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/bpe/train-bpe.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "Lvv19Hzz4QMR",
        "outputId": "7bb066ea-55c2-455a-b1f1-dc46b26817eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some are against it .\n",
            "&#91; foot@@ note &#93; ca@@ per@@ na@@ um was considered to be jesus home city in the district of gal@@ ile@@ e. mark 2 : 1 .\n",
            "pm narendra modi and amit shah have already held rallies in the state .\n",
            "child@@ ren@@ s education\n",
            "in many places there had been clashes .\n",
            "he had joined bjp before the rajya sabha polls .\n",
            "uddhav thackeray had visited ayodhya before the lok sabha polls .\n",
            "further arre@@ sts are expected in the future .\n",
            "dont like it .\n",
            "so , lets say we just put one electro@@ de of li@@ thi@@ um here another electro@@ de of something some counter electro@@ de here .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 data/bpe/train-bpe.mr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "swv_Mp1b4VhO",
        "outputId": "d4bb4b8e-17b8-4118-9e3c-3955516ffef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तर काही जण विरोध@@ ही करत आहेत . \n",
            "या माहि@@ तीचे परीक्षण करताना आपल्याला कळ@@ ेल , की आजही येशू@@ चा लोकां@@ वर प्रभाव का पडत आहे . ( w@@ १० - E ०@@ ४ / ०@@ १ ) \n",
            "नरेंद्र मोदी आणि अमित शहा यांनी देशात अ@@ राज@@ क माज@@ वले आहे . \n",
            "मुला@@ चे शिक्षण\n",
            "अनेक ठिकाणी पड@@ झ@@ डीच्या घटना घडल्या . \n",
            "मात्र विधानसभा निवडणुकी@@ आधी ते भाजपमध्ये गेले . \n",
            "लोकसभा निवडणुकीच्या आधी पक्षप्रमुख उद्धव ठाकरे यांनी अयो@@ ध्ये@@ चा दौरा केला होता . \n",
            "येत्या काळात आणखी काही@@ ंची धर@@ प@@ कड केली जाण्याची शक्यता आहे . \n",
            "अजिबात आवड@@ ला नाही . \n",
            "तर , आपण इथे लि@@ थि@@ य@@ मचे एक इलेक्@@ ट्रो@@ ड ( e@@ le@@ c@@ tr@@ o@@ d@@ e ) ठेवू या . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Vocabulary**"
      ],
      "metadata": {
        "id": "HWfe_sMFrS0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data/pre\n",
        "vocab = \"\"\"\n",
        "save_data: data/pre\n",
        "\n",
        "src_vocab: data/pre/vocab.en\n",
        "tgt_vocab: data/pre/vocab.mr\n",
        "\n",
        "overwrite: False\n",
        "\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: data/bpe/train-bpe.en\n",
        "        path_tgt: data/bpe/train-bpe.mr\n",
        "\"\"\"\n",
        "\n",
        "createVocabYaml = open(\"vocab.yaml\", 'w+')\n",
        "createVocabYaml.write(vocab)\n",
        "createVocabYaml.close() \n",
        "\n",
        "!onmt_build_vocab -config vocab.yaml -n_sample -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "7BwF8xNcrF0P",
        "outputId": "d945243e-945f-4c0e-f8f0-41f1bfda6b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2022-04-06 18:36:49,237 INFO] Counter vocab from -1 samples.\n",
            "[2022-04-06 18:36:49,237 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2022-04-06 18:36:49,250 INFO] corpus_1's transforms: TransformPipe()\n",
            "[2022-04-06 18:36:50,357 INFO] Counters src:7927\n",
            "[2022-04-06 18:36:50,357 INFO] Counters tgt:8322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train NMT Model**"
      ],
      "metadata": {
        "id": "g9TmAtlPtwk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!mkdir tensorboard\n",
        "\n",
        "train = \"\"\"\n",
        "\n",
        "save_data: data/pre\n",
        "\n",
        "src_vocab: data/pre/vocab.mr\n",
        "tgt_vocab: data/pre/vocab.en\n",
        "\n",
        "overwrite: False\n",
        "\n",
        "src_seq_length: 200\n",
        "tgt_seq_length: 200\n",
        "\n",
        "data:\n",
        "    corpus_1:\n",
        "      path_src: data/bpe/train-bpe.en\n",
        "      path_tgt: data/bpe/train-bpe.mr\n",
        "      transforms: [filtertoolong]\n",
        "    valid:\n",
        "      path_src: data/bpe/valid-bpe.en\n",
        "      path_tgt: data/bpe/valid-bpe.mr\n",
        "      transforms: [filtertoolong]\n",
        "\n",
        "# Training\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "master_port: 5001\n",
        "\n",
        "# General opts\n",
        "log_file: checkpoints/log.txt\n",
        "save_model: checkpoints/model\n",
        "tensorboard_log_dir: \"tensorboard\"\n",
        "tensorboard: true\n",
        "keep_checkpoint: 20\n",
        "save_checkpoint_steps: 10000\n",
        "average_decay: 0.0005\n",
        "seed: 1234\n",
        "report_every: 1\n",
        "train_steps: 300000\n",
        "valid_steps: 10000\n",
        "\n",
        "# Batching\n",
        "queue_size: 10000\n",
        "bucket_size: 32768\n",
        "pool_factor: 8192\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096\n",
        "valid_batch_size: 16\n",
        "batch_size_multiple: 1\n",
        "max_generator_batches: 0\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta1: 0.9\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0.0\n",
        "param_init_glorot: \"true\"\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "enc_layers: 3\n",
        "dec_layers: 3\n",
        "heads: 4\n",
        "rnn_size: 256\n",
        "dec_rnn_size: 256\n",
        "word_vec_size: 256\n",
        "transformer_ff: 1024\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "share_decoder_embeddings: \"true\"\n",
        "position_encoding: \"true\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "trainYaml = open(\"train.yaml\", 'w+')\n",
        "trainYaml.write(train)\n",
        "trainYaml.close() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "esqGQmvhtzWl",
        "outputId": "53fdff94-a1c2-4324-cef8-517a526a1dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! CUDA_VISIBLE_DEVICES=0 onmt_train -config train.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XKW43JM0vDkA",
        "outputId": "ab548011-9965-4356-a4e8-8005883ca505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-12-19 07:45:30,834 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2021-12-19 07:45:30,834 INFO] Parsed 2 corpora from -data.\n",
            "[2021-12-19 07:45:30,834 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
            "[2021-12-19 07:45:30,834 INFO] Loading vocab from text file...\n",
            "[2021-12-19 07:45:30,834 INFO] Loading src vocabulary from data/pre/vocab.mr\n",
            "[2021-12-19 07:45:30,856 INFO] Loaded src vocab has 8322 tokens.\n",
            "[2021-12-19 07:45:30,860 INFO] Loading tgt vocabulary from data/pre/vocab.en\n",
            "[2021-12-19 07:45:30,877 INFO] Loaded tgt vocab has 7927 tokens.\n",
            "[2021-12-19 07:45:30,882 INFO] Building fields with vocab in counters...\n",
            "[2021-12-19 07:45:30,891 INFO]  * tgt vocab size: 7931.\n",
            "[2021-12-19 07:45:30,903 INFO]  * src vocab size: 8324.\n",
            "[2021-12-19 07:45:30,904 INFO]  * src vocab size = 8324\n",
            "[2021-12-19 07:45:30,904 INFO]  * tgt vocab size = 7931\n",
            "[2021-12-19 07:45:30,907 INFO] Building model...\n",
            "[2021-12-19 07:45:40,817 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(8324, 256, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(7931, 256, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_values): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (linear_query): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=7931, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2021-12-19 07:45:40,821 INFO] encoder: 4500736\n",
            "[2021-12-19 07:45:40,821 INFO] decoder: 5199099\n",
            "[2021-12-19 07:45:40,821 INFO] * number of parameters: 9699835\n",
            "[2021-12-19 07:45:43,471 INFO] Starting training on GPU: [0]\n",
            "[2021-12-19 07:45:43,471 INFO] Start training loop and validate every 10000 steps...\n",
            "[2021-12-19 07:45:43,472 INFO] corpus_1's transforms: TransformPipe(FilterTooLongTransform(src_seq_length=200, tgt_seq_length=200))\n",
            "[2021-12-19 07:45:43,472 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2021-12-19 07:45:51,580 INFO] Step  1/300000; acc:   4.97; ppl: 1500.63; xent: 7.31; lr: 0.00000; 1182/1639 tok/s;      8 sec\n",
            "[2021-12-19 07:45:53,990 INFO] Step  2/300000; acc:  12.23; ppl: 1468.08; xent: 7.29; lr: 0.00000; 2034/2186 tok/s;     11 sec\n",
            "[2021-12-19 07:45:58,485 INFO] Step  3/300000; acc:   4.64; ppl: 1566.03; xent: 7.36; lr: 0.00000; 2161/2788 tok/s;     15 sec\n",
            "[2021-12-19 07:46:02,240 INFO] Step  4/300000; acc:   6.93; ppl: 1517.12; xent: 7.32; lr: 0.00000; 2427/2714 tok/s;     19 sec\n",
            "[2021-12-19 07:46:05,289 INFO] Step  5/300000; acc:  12.91; ppl: 1401.48; xent: 7.25; lr: 0.00000; 2766/2853 tok/s;     22 sec\n",
            "[2021-12-19 07:46:07,810 INFO] Step  6/300000; acc:  16.27; ppl: 1359.10; xent: 7.21; lr: 0.00000; 3038/3297 tok/s;     24 sec\n",
            "[2021-12-19 07:46:12,121 INFO] Step  7/300000; acc:   9.86; ppl: 1449.91; xent: 7.28; lr: 0.00000; 2966/3305 tok/s;     29 sec\n",
            "[2021-12-19 07:46:15,698 INFO] Step  8/300000; acc:  11.17; ppl: 1418.72; xent: 7.26; lr: 0.00000; 3294/3641 tok/s;     32 sec\n",
            "[2021-12-19 07:46:19,238 INFO] Step  9/300000; acc:  12.74; ppl: 1415.59; xent: 7.26; lr: 0.00000; 2556/3377 tok/s;     36 sec\n",
            "[2021-12-19 07:46:23,381 INFO] Step 10/300000; acc:  15.77; ppl: 1389.06; xent: 7.24; lr: 0.00000; 2777/2792 tok/s;     40 sec\n",
            "[2021-12-19 07:46:25,697 INFO] Step 11/300000; acc:  20.63; ppl: 1364.98; xent: 7.22; lr: 0.00000; 2183/3041 tok/s;     42 sec\n",
            "[2021-12-19 07:46:29,221 INFO] Step 12/300000; acc:  21.99; ppl: 1403.67; xent: 7.25; lr: 0.00000; 3001/3140 tok/s;     46 sec\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_train\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/train.py\", line 172, in main\n",
            "    train(opt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/train.py\", line 157, in train\n",
            "    train_process(opt, device_id=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/train_single.py\", line 114, in main\n",
            "    valid_steps=opt.valid_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/trainer.py\", line 244, in train\n",
            "    report_stats)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/trainer.py\", line 383, in _gradient_accumulation\n",
            "    self.optim.backward(loss)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/utils/optimizers.py\", line 329, in backward\n",
            "    self._scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "JoLGUvZew1tF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Covid-19 Test Set"
      ],
      "metadata": {
        "id": "9iLzwrdLv9BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/drive/folders/1hy80UglVd7dUA_osGbl50BF4NWbp2msd?usp=sharing'\n",
        "gdown.download_folder(url, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "nBJqPVPMu9JB",
        "outputId": "cd6e1e11-c2b0-44ec-a0f5-229a025e4c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/covid-19-testset/test.en', '/content/covid-19-testset/test.mr']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download WAT 2021 testset"
      ],
      "metadata": {
        "id": "8DD6j2TGtA7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/drive/folders/1v6B21vqxkvq86bAwQlzFFCDXpVklp7Zq?usp=sharing'\n",
        "gdown.download_folder(url, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "tg7zlnHmtEQ1",
        "outputId": "e6505688-6699-4739-9455-cc96d20a0d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wat2021/test.en', '/content/wat2021/test.hi']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Translate**"
      ],
      "metadata": {
        "id": "rU1cAh284rTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Uncomment if the part after `if __name__ == '__main__':` in the file `indic_nlp_library/indicnlp/tokenize/indic_tokenize.py`"
      ],
      "metadata": {
        "id": "bYFM8zg4UnGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test\n",
        "\n",
        "!/content/mosesdecoder/scripts/tokenizer/lowercase.perl < covid-19-testset/test.en > covid-19-testset/test-low.en\n",
        "!/content/mosesdecoder/scripts/tokenizer/tokenizer.perl < covid-19-testset/test-low.en > covid-19-testset/test-tok.en\n",
        "!subword-nmt apply-bpe -c codes/codes.en < covid-19-testset/test-tok.en > covid-19-testset/test-bpe.en\n",
        "\n",
        "\n",
        "#check the name of model files on dir \"checkpoints/\" before running.\n",
        "! CUDA_VISIBLE_DEVICES=0 onmt_translate \\\n",
        "        -gpu 0 \\\n",
        "        -batch_size 4096 -batch_type tokens \\\n",
        "        -beam_size 5 \\\n",
        "        -model checkpoints/model.pt \\\n",
        "        -src covid-19-testset/test-bpe.en \\\n",
        "        -output test/test.mr \\\n",
        "        -replace_unk\n",
        "    \n",
        "! sed -r -i 's/(@@ )|(@@ ?$)//g' test/test.mr\n",
        "\n",
        "! sed -r -i 's/ &amp;apos;//g' test/test.mr\n",
        "\n",
        "!python3 indic_nlp_library/indicnlp/tokenize/indic_detokenize.py test/test.mr test/test-detok.mr mr\n"
      ],
      "metadata": {
        "id": "M4PJDPwcvn1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "635c6e23-f17b-4500-b4cf-d94bb562fd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 1\n",
            "[2021-12-19 10:13:34,830 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2021-12-19 10:14:22,644 INFO] PRED AVG SCORE: -0.6487, PRED PPL: 1.9131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compute BLEU score**"
      ],
      "metadata": {
        "id": "wAg3Fx3-k2tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "hypothesis = open(\"test/test-detok.mr\", 'r').readlines()\n",
        "reference = open(\"covid-19-testset/test.mr\", 'r').readlines()\n",
        "\n",
        "hypothesisSentences, referenceSentences = [], []\n",
        "\n",
        "for i in range(len(hypothesis)):\n",
        "    hypothesisSentence = hypothesis[i].strip(\"\\n\")\n",
        "    referenceSentence = reference[i].strip(\"\\n\")\n",
        "    hypothesisSentences.append(hypothesisSentence)\n",
        "    referenceSentences.append(referenceSentence)\n",
        "\n",
        "bleu = sacrebleu.corpus_bleu(hypothesisSentences, [referenceSentences])\n",
        "print(bleu.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "D1P5CZwDk2KQ",
        "outputId": "bb84de89-9b01-44d5-b132-72e624391d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.14265478509391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment** "
      ],
      "metadata": {
        "id": "prIaMZu36kZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ctranslate2\n",
        "\n",
        "model = \"checkpoints/model.pt\"\n",
        "converter = ctranslate2.converters.OpenNMTPyConverter(model)\n",
        "\n",
        "!mkdir model_deploy \n",
        "output = \"model_deploy\"\n",
        "converter.convert(output,\n",
        "    force=True,\n",
        "    # quantization=\"int8\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "1XG0Hkrkoy4f",
        "outputId": "4725dbab-b5c3-4f83-972d-4ffa0b2597dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model_deploy'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mosestokenizer import MosesSentenceSplitter, MosesTokenizer\n",
        "\n",
        "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "\n",
        "import codecs\n",
        "from subword_nmt.apply_bpe import BPE\n"
      ],
      "metadata": {
        "id": "tslI_NOs6oUD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "de00732f-9b63-402d-93e7-326945bae39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenize\n",
        "englishTokenizer = MosesTokenizer('en')\n",
        "## BPE\n",
        "englishBpeCodes = codecs.open(\"codes/codes.en\", encoding='utf-8')\n",
        "englishBpeEncoder = BPE(englishBpeCodes)\n",
        "## Translator\n",
        "translator = ctranslate2.Translator(\"model_deploy\",\n",
        "    # compute_type=\"int8\"\n",
        "    )\n",
        "\n",
        "sourceSentence = input(\"Enter English Sentence: \")\n",
        "\n",
        "# Lowercase\n",
        "sourceSentence = sourceSentence.lower()\n",
        "\n",
        "# Tokenize\n",
        "sourceSentence = ' '.join(englishTokenizer(sourceSentence))\n",
        "\n",
        "# Apply BPE\n",
        "sourceSentence = englishBpeEncoder.process_line(sourceSentence).split(\" \")\n",
        "\n",
        "# Translate\n",
        "targetSentence = translator.translate_batch([sourceSentence], beam_size=5, max_batch_size=16)\n",
        "\n",
        "# Remove BPE\n",
        "targetSentence = (' '.join(targetSentence[0].hypotheses[0]) + \" \").replace(\"@@ \", \"\")\n",
        "\n",
        "print(\"Marathi Sentence:\", targetSentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "69LErUAWonbu",
        "outputId": "56bfb7f6-e42e-4072-ebdb-a91fb09c017a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  for (rule of document.styleSheets[0].cssRules){\n",
              "    if (rule.selectorText=='body') {\n",
              "      rule.style.fontSize = '20px'\n",
              "      break\n",
              "    }\n",
              "  }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter English Sentence: Rivers in India play an important role in the lives of people.\n",
            "Marathi Sentence: भारतातील नद्या लोकांच्या जीवनात महत्त्वाची भूमिका बजावतात . \n"
          ]
        }
      ]
    }
  ]
}